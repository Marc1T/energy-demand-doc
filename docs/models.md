# Mod√®les de pr√©vision

Dans ce projet, nous avons test√© plusieurs mod√®les de machine learning et de deep learning pour pr√©dire la demande √©lectrique en Espagne √† diff√©rentes √©chelles temporelles (horaire et journali√®re). Chaque mod√®le a √©t√© √©valu√© sur ses performances de pr√©diction, sa robustesse et sa capacit√© √† g√©n√©raliser selon les zones g√©ographiques.

---

## 1. Mod√®les classiques de Machine Learning

### üéØ R√©gression Ridge

- **Principe** : Variante de la r√©gression lin√©aire avec r√©gularisation L2 pour √©viter le surapprentissage.
- **Pourquoi l'utiliser ?** : Simple, rapide et efficace avec des s√©ries temporelles bien pr√©trait√©es.
- **Utilisation dans le projet** :
  - Test√© comme baseline.
  - Bonnes performances sur certaines zones, notamment "Baleares" et "Peninsule_Iberique".
- **Avantages** :
  - Interpr√©table.
  - Faible co√ªt computationnel.
- **Inconv√©nients** :
  - Faible capacit√© √† mod√©liser la non-lin√©arit√©.

üì∑ *[Inclure ici un screenshot de la pr√©diction Ridge vs r√©alit√©]*

---

### üéØ ElasticNet

- **Principe** : Combine r√©gularisation L1 (Lasso) et L2 (Ridge).
- **Pourquoi l'utiliser ?** : Utile quand plusieurs features sont corr√©l√©es.
- **Utilisation dans le projet** : Meilleur mod√®le sur certaines zones comme "Melilla".
- **Avantages** :
  - S√©lectionne automatiquement les variables pertinentes.
- **Limites** :
  - Moins stable sur les petites s√©ries.

---

### üå≥ Random Forest

- **Principe** : Ensemble de plusieurs arbres de d√©cision entra√Æn√©s sur des sous-√©chantillons.
- **Pourquoi l'utiliser ?** : Tr√®s robuste, performant sur des donn√©es non lin√©aires.
- **Utilisation dans le projet** :
  - Meilleur mod√®le horaire dans la majorit√© des zones.
  - √âgalement utilis√© en journalier.
- **Avantages** :
  - Pr√©dictions stables.
  - G√®re les interactions implicites entre variables.
- **Inconv√©nients** :
  - Moins interpr√©table.
  - Plus lent √† entra√Æner.

üì∑ *[Inclure un graphe RF : importance des variables]*

---

### ‚ö° LightGBM

- **Principe** : Boosting d'arbres (Gradient Boosting) tr√®s rapide.
- **Pourquoi l'utiliser ?** : Excellente performance pour les probl√®mes structur√©s.
- **Utilisation dans le projet** : Test√© mais parfois battu par Random Forest.
- **Avantages** :
  - Efficace en entra√Ænement.
  - G√®re bien les s√©ries avec bruit.
- **Limites** :
  - Sensible √† l'overfitting sans r√©glage.

---

### ‚è≥ ARIMA (AutoRegressive Integrated Moving Average)

- **Principe** : Mod√©lisation bas√©e uniquement sur la s√©rie pass√©e.
- **Pourquoi l'utiliser ?** : Baseline statistique fiable.
- **Utilisation dans le projet** :
  - Mod√®le de r√©f√©rence sur s√©ries stationnaires.
  - Moins comp√©titif que les mod√®les ML en cas de forte variabilit√©.
- **Avantages** :
  - Interpr√©table et th√©oriquement solide.
- **Limites** :
  - Ne prend pas en compte les variables exog√®nes.
  - Moins performant sur des s√©ries complexes.

---

## 2. Mod√®les Deep Learning

### üß† LSTM (Long Short-Term Memory)

- **Principe** : R√©seau de neurones r√©currents adapt√© √† la m√©moire √† long terme.
- **Pourquoi l'utiliser ?** : Excellent pour capturer des d√©pendances temporelles lointaines.
- **Utilisation dans le projet** :
  - Pr√©vision de la demande horaire et journali√®re.
  - Exige un preprocessing soign√©.
- **Avantages** :
  - Prend en compte le contexte historique.
- **Inconv√©nients** :
  - Long √† entra√Æner.
  - Sensible aux hyperparam√®tres.

üì∑ *[Inclure courbe d'apprentissage + pr√©diction LSTM vs r√©elle]*

---

### üîÅ GRU (Gated Recurrent Unit)

- **Principe** : Variante simplifi√©e de LSTM.
- **Pourquoi l'utiliser ?** : Moins co√ªteux que LSTM, performances souvent comparables.
- **Utilisation dans le projet** :
  - Utilis√© comme alternative √† LSTM.
- **Avantages** :
  - Moins de param√®tres.
- **Limites** :
  - L√©g√®rement moins performant pour de longues d√©pendances.

---

### üß© CNN-1D

- **Principe** : Applique des filtres convolutifs sur les s√©ries pour d√©tecter des patterns locaux.
- **Pourquoi l'utiliser ?** : Tr√®s bon pour d√©tecter des motifs cycliques.
- **Utilisation dans le projet** :
  - Pr√©vision sur des s√©quences fixes (input sliding window).
- **Avantages** :
  - Rapide et efficace.
- **Limites** :
  - Contexte temporel plus local que LSTM/GRU.

---

### üîÄ CNN-LSTM

- **Principe** : Combine un bloc CNN (extraction de motifs) + LSTM (s√©quence).
- **Pourquoi l'utiliser ?** : Combine les points forts des deux approches.
- **Utilisation dans le projet** :
  - Pr√©vision avanc√©e avec s√©quence d‚Äôentr√©e multi-feature.
- **Avantages** :
  - Tr√®s performant si bien calibr√©.
- **Inconv√©nients** :
  - Co√ªt d'entra√Ænement √©lev√©.

---

## üß™ S√©lection des meilleurs mod√®les

Apr√®s entra√Ænement, chaque mod√®le a √©t√© √©valu√© √† l‚Äôaide de :
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- MAPE (Mean Absolute Percentage Error)

Les meilleurs mod√®les par zone ont √©t√© automatiquement s√©lectionn√©s puis sauvegard√©s :

```text
üìÅ submission/
‚îú‚îÄ‚îÄ Peninsule_Iberique_processed_hourly.parquet
‚îú‚îÄ‚îÄ Melilla_processed_daily.parquet
‚îú‚îÄ‚îÄ features_selected_hourly.csv
‚îú‚îÄ‚îÄ best_models.csv
```
metrics pas tres bons pour les modeles deep
```csv
zone,horizon,model,MAE,RMSE,MAPE
Ceuta,daily,LSTM,294.184478086403,297.5592351506879,79.46752716653282
Ceuta,daily,GRU,290.5378141736367,293.860330991986,79.22204350660417
Ceuta,daily,CNN,44.61273922839268,80.9607488539366,50.97870938287471
Ceuta,daily,CNN-LSTM,291.22003079047994,294.55189605442234,79.26797527424722
Ceuta,hourly,LSTM,0.6781376151244601,1.239811621017631,inf
Ceuta,hourly,GRU,0.6156814975927049,1.2077079105214479,inf
Ceuta,hourly,CNN,0.7745091407810173,1.5464381211602554,inf
Ceuta,hourly,CNN-LSTM,0.5962147199231576,1.1674468191333844,inf
```
pourtant on a de bon resultats avec les modeles classiques.
```csv
zone,daily_ElasticNet_MAE,daily_ElasticNet_RMSE,daily_ElasticNet_MAPE,daily_Ridge_MAE,daily_Ridge_RMSE,daily_Ridge_MAPE,daily_RandomForest_MAE,daily_RandomForest_RMSE,daily_RandomForest_MAPE,daily_auto_arima_MAE,daily_auto_arima_RMSE,daily_auto_arima_MAPE,hourly_ElasticNet_MAE,hourly_ElasticNet_RMSE,hourly_ElasticNet_MAPE,hourly_Ridge_MAE,hourly_Ridge_RMSE,hourly_Ridge_MAPE,hourly_RandomForest_MAE,hourly_RandomForest_RMSE,hourly_RandomForest_MAPE,hourly_auto_arima_MAE,hourly_auto_arima_RMSE,hourly_auto_arima_MAPE
Ceuta,0.014531369384538452,0.019753042463590328,0.011075109418962639,0.00020269046454933297,0.0002574187522392442,0.00013044864687825013,19.26567012477717,31.865167651828283,5.206201858597312,49.81000526183854,100.7861014693329,69.04778687335315,0.8051295554100869,1.4303024831726077,inf,0.7740636064212212,1.4207898605458968,inf,0.49929184159544143,1.0516865447893236,inf,inf,inf,inf
```
---

## ‚úÖ R√©sum√©

Chaque mod√®le a √©t√© test√© de mani√®re rigoureuse, avec :

* Pr√©traitement sp√©cifique par zone.
* S√©lection de features contextuelles.
* Validation crois√©e (CV).
* S√©lection automatique du meilleur algorithme.

‚û°Ô∏è Voir la section [R√©sultats](results.md) pour les scores d√©taill√©s et la robustesse des mod√®les.


